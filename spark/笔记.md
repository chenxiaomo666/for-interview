## 背景

视频：https://www.bilibili.com/video/BV1Jq4y1z7VP/?spm_id_from=333.337.search-card.all.click&vd_source=59101a7b5e6403f5c3656d1e6ac848cb

当前进度：P25

## 一、Spark基础入门

### 第一章

#### Spark的factor

* Spark是基于内存做计算的，弹性分布式数据集（即RDD）的概念：RDD是一种分布式内存抽象，其使得程序员能够在大规模集群中做内存运算，并且有一定的容错方式。而这也是整个Spark的核心数据结构，Spark整个平台都围绕着RDD进行。

* Spark支持pandas

* 速度快

  > 1、spark在处理数据时，可以将中间处理结果数据存储到内存中（内存迭代计算）；
  >
  > 2、Spark提供了非常丰富的算子(API)，可以做到复杂任务在一个Spark程序中完成。

* 运行方式

  > Spark支持多种运行方式，包括在Hadoop和Mesos上，也支持Standalone的独立运行模式。
  >
  > 对于数据而言，Spark支持从HDFS、HBase、Cassandra及kafka等多种途径获取数据

* Spark框架模块

  > 1、SparkCore：Spark的核心，Spark核心公告均有Spark Core模块提供，是Spark运行的基础。Spark Core以RDD为数据抽象，提供python、java、scala、R语言的API，可以编程进行海量离线数据批处理计算；
  >
  > 2、SparkSQL：基于SparkCore之上，提供**结构化**数据处理模块。SparkSQL支持以SQL语言对数据进行处理，SparkSQL本身针对离线计算场景。同时基于SparkSQL，Spark提供了StructuredStreaming模块（真正的流计算？），可以以SparkSQL为基础，进行数据的流式计算。
  >
  > 3、SparkStreaming：以SpakCore为基础，提供数据的流式计算（是一个微小时间段的批处理）。
  >
  > 4、MLib：以SparkCore为基础，进行机器学习计算，内置了大量的机器学习库和API算法等。方便用户以分布式计算的模式进行机器学习计算。
  >
  > 5、GraphX：以SparkCore为基础，进行图计算，提供了大量的图计算API，方便用于分布式计算模式进行图计算。

* **Spark的运行模式（面试也遇到过）**

  > master和worker
  >
  > 1、本地模式（单机）：也被称为Local模式，用于开发和测试环境。本地模式就是以一个独立的进程，通过其内部的多个线程来模拟整个Spark运行时环境。
  >
  > 2、Standalone模式（集群）：Spark中的各个角色以独立进程的形式存在，并组成Spark集群环境。
  >
  > 3、Hadoop YARN模式（集群）：Spark中的各个角色运行在YARN的容器内部，并组成Spark集群环境。
  >
  > 4、Kubernetes模式（容器集群）：Spark中的各个角色运行在Kubernetes的容器内部，并组成Spark集群环境。

#### Spark的架构角色

YARN角色回顾：

YARN主要有4类角色，从2个层面去看。

![image-20231223160324381](https://20178666.oss-cn-beijing.aliyuncs.com/img/image-20231223160324381.png)

资源管理层面：

* 集群资源管理者（Master）：ResourceManager
* 单机资源管理者（Worker）：NodeManager

任务计算层面：

* 单任务管理者（Master）:ApplicationMaster
* 单任务执行者（Worker）：Task（容器内计算框架的工作角色）

Spark运行角色：

![image-20231223160725975](https://20178666.oss-cn-beijing.aliyuncs.com/img/image-20231223160725975.png)

资源层面：

* master：集群资源管理
* worker：单机资源管理

任务运行层面：

* driver：单个任务管理
* executor：单个任务的计算（worker 干活的）

> 注：正常情况下Executor是干活的角色，不过在特殊场景下（Local模式）Driver可以即管理又干活。

#### （重点：面试常见）Spark和Hadoop（MapReduce）的对比

![image-20231223104636681](https://20178666.oss-cn-beijing.aliyuncs.com/img/image-20231223104636681.png)

* 类型：hadoop是基础平台，包含计算、存储和调度；spark是一个纯计算工具
* 场景：hadoop是海量数据批处理（基于磁盘迭代计算）；spark是海量数据的批处理（内存迭代计算、交互式计算）、海量数据流计算。
* 价格：hadoop对机器要求低，便宜；spark对内存有要求，相对较贵
* 编程范式：hadoop是map+reduce，API较为底层，算法适应性差；spark是采用RDD组成有向无环图，API较为顶层，方便使用。
* 数据存储结构：MapReduce中间计算结果在HDFS磁盘上，延迟比较大；spark的RDD中间运算结果在内存中，延迟小。
* 运行方式：hadoop的task以进程方式维护，任务启动慢；spark的task以线程方式维护，任务启动快，可批量创建提高并行能力。

#### 为什么Spark相对于Hadoop而言有较大的优势，但是Spark并不能完全替代Hadoop呢？

* 在计算层面，Spark相比较于MapReduce有巨大的性能优势，但是至今仍有很多计算工具基于MapReduce框架，比如非常成熟的Hive。
* Spark仅做计算，而Hadoop生态圈不仅有计算（MR）也有存储（HDFS）和资源管理调度（YARN），HDFS和YARN仍是许多大数据体系的核心架构。

### 第二章

#### 2.1 课程服务器环境

他要搭建三台Linux虚拟机服务器。做集群。但是我就准备在windows本机上做一个local环境，能写能跑代码就行，不然搭建环境又是十分麻烦费时的工作。继续启动。

#### 2.2 Local模式基本原理

本质：启动一个JVM Process进程（一个进程里面有多个线程），执行任务Task

Spark中Task以线程Thread方式进行

每个Task运行需要1 Core Cpu

* Local模式可以限制模拟Spark集群环境的线程数量，即Local[N]或者Local[*]
* 其中N代表可以使用N个线程，每个线程拥有一个cpu core。如果不指定N，则默认是1个线程（该线程有1个core）。通常Cpu有几个核就指定几个线程，最大化利用计算能力。
* 如果是local[*]，则代表Run Spark locally with as many worker threads as logical cores on your machine.按照cpu最多的cores设置线程数。

Local下的角色分布：

资源管理

* master：Local进程本身
* worker：Local进程本身

任务执行

Driver：Local进程本身

Executor：不存在，没有独立的Executor角色，由Local进程(也就是Driver）内的线程提供计算能力。

> 注：Driver也算一种特殊的Executor，只不过多数时候，我们将Executor当作纯Worker对待，这样额Driver好区分（一类是管理，一类是工人）
>
> 另：Local模式只能运行一个Spark程序，如果执行多个Spark程序，那就是由多个相互独立的Local进程在执行。

spark监控页面：http://127.0.0.1:4040/jobs/

#### 2.3 安装包下载

#### 2.4 基础操作

#### 2.5 测试

### 第三章

#### Stabdalone架构

Standalone是完整的Spark运行环境，其中master角色以master进程存在，worker角色以worker进程存在，driver角色在运行时存在于master进程内，executor运行于worker进程内。

#### Spark程序运行层次结构

* 4040端口页面：是一个运行的Application在运行的过程中临时绑定的端口，用以查看当前任务的状态。它是一个临时端口，当前程序运行完成后，4040会被注销。
* 8080端口页面：默认是Standalone下，master进程的WEB端口，用以查看当前master集群的状态。
* 18080端口页面：默认是历史服务器的端口，由于每个程序运行完后，4040端口被注销了，在以后想回看讴歌程序的运行状态就可以通过历史服务器查看，历史服务器长期稳定运行，可供随时查看被记录的程序的运行过程。

#### job、stage、task的关系

一个Spark程序会被分成多个子任务（job），每一个job会被分成多个Stage（阶段）来运行，每一个stage内会分出多个task（线程）来执行具体任务

### 第四章

#### StandAlone HA的原理

基于Zookeeper做状态的维护，开启多个Master进程，一个作为活跃，其他的作为备份，当活跃进程挂了，备份master接管。

### 第五章

#### Spark On YARN

对于Spark On YARN，无需部署Spark集群，只需要找一台服务器，充当Spark的客户端，即可提交任务到YARN集群中运行。

#### 本质

* Spark On YARN的本质

  > master角色由YARN的resourceManager担任
  >
  > worker角色由YARN的NodeManager担任
  >
  > driver角色运行在YARN容器内，或提交任务的客户端进程中。
  >
  > 真正干活的Executor运行在YARN提供的容器内。

* Spark On YARN需要啥

  > 1、需要的YARN集群已经安装了；
  >
  > 2、需要Spark客户端工具，比如spark-submit，可以将Spark程序提交到YARN中；
  >
  > 3、需要被提交的代码程序。（这不废话吗，） 

#### 运行模式

Spark On YARN有两种运行模式的，一种是Cluster（集群）模式，一种是Client模式。这两种模式的区别就是Driver运行的位置。

![image-20231224143200511](https://20178666.oss-cn-beijing.aliyuncs.com/img/image-20231224143200511.png)

* Cluster模式：即Driver运行在YARN容器内部，和ApplicationMaster在同一个容器内。（通信效率高）
* Client模式：Driver运行在客户端进程中，比如Driver运行在spark-submit程序的进程中。（看日志，print或者debug日志输出方便，直接在client终端就可以看到）

### 第六章

### 第七章

### 第八章

## 二、SparkCore

### 第一章

### 第二章

### 第三章

### 第四章

### 第五章

### 第六章

## 三、SparkSQL

### 第一章

### 第二章

### 第三章

### 第四章

### 第五章

### 第六章

### 第七章

## 四、案例

### 案例背景

### 需求一开发

### 需求二开发

### 需求三开发

### 需求四开发

## 五、Spark新特性及核心回顾

### 第一章

### 第二章

### 第三章